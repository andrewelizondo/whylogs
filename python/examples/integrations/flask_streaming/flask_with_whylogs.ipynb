{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Integrating Whylogs into your Flask Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pandas utils joblib scikit-learn whylogs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import urllib.request as urllib\n",
    "import requests\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Grab the Data and Prep it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'dataset' directory already existed. Moving forward\n"
     ]
    }
   ],
   "source": [
    "# Download Iris dataset and save it as csv\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "raw_data = urllib.urlopen(url)\n",
    "try:\n",
    "    os.mkdir(\"dataset/\")\n",
    "except Exception as e:\n",
    "    print(\" 'dataset' directory already existed. Moving forward\")\n",
    "# Save data as csv\n",
    "with open('dataset/Iris.csv', 'wb') as file:\n",
    "    file.write(raw_data.read())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/Iris.csv', header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Separating the independent variables from dependent variables\n",
    "X = data.iloc[:, 0:4].values\n",
    "y = data.iloc[:, -1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Train the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train started.\n",
      "Train finished.\n",
      "Model saved as model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier\n",
    "print(\"Train started.\")\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Train finished.\")\n",
    "# Save the model\n",
    "dump(model, 'model.joblib')\n",
    "print(\"Model saved as model.joblib\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Build and Run a Docker Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1A\u001B[1B\u001B[0G\u001B[?25l[+] Building 0.0s (0/1)                                                         \r\n",
      "\u001B[?25h\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.2s (2/3)                                                         \r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 37B                                        0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 34B                                           0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.9              0.1s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.3s (2/3)                                                         \r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 37B                                        0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 34B                                           0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.9              0.2s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.5s (2/3)                                                         \r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 37B                                        0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 34B                                           0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.9              0.4s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.6s (10/10)                                                       \r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 37B                                        0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 34B                                           0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.9              0.4s\r\n",
      "\u001B[0m\u001B[34m => [1/6] FROM docker.io/library/python:3.9@sha256:51c996c8c65d826d20c613  0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 18.83kB                                       0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [2/6] RUN mkdir /app                                            0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [3/6] WORKDIR /app                                              0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [4/6] COPY requirements.txt .                                   0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [5/6] RUN pip install --no-cache-dir -r requirements.txt        0.0s\r\n",
      "\u001B[0m\u001B[34m => [6/6] COPY ./ /app                                                     0.0s\r\n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.6s (11/11) FINISHED                                              \r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 37B                                        0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 34B                                           0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.9              0.4s\r\n",
      "\u001B[0m\u001B[34m => [1/6] FROM docker.io/library/python:3.9@sha256:51c996c8c65d826d20c613  0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 18.83kB                                       0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [2/6] RUN mkdir /app                                            0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [3/6] WORKDIR /app                                              0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [4/6] COPY requirements.txt .                                   0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [5/6] RUN pip install --no-cache-dir -r requirements.txt        0.0s\r\n",
      "\u001B[0m\u001B[34m => [6/6] COPY ./ /app                                                     0.0s\r\n",
      "\u001B[0m\u001B[34m => exporting to image                                                     0.0s\r\n",
      "\u001B[0m\u001B[34m => => exporting layers                                                    0.0s\r\n",
      "\u001B[0m\u001B[34m => => writing image sha256:ab836fddf80df1da8427b7889ca23850b2601eefb4114  0.0s\r\n",
      "\u001B[0m\u001B[34m => => naming to docker.io/library/whylogs-flask                           0.0s\r\n",
      "\u001B[0m\u001B[?25h\r\n",
      "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\r\n"
     ]
    }
   ],
   "source": [
    "!docker build --build-arg PYTHON_VERSION=3.9 -t whylogs-flask ."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Open a terminal and execute the following command:\n",
    "\n",
    "```bash\n",
    "docker run --rm -p 5000:5000 whylogs-flask\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Test Endpoint and Visualize \n",
    "TODO: Bring in the NotebookProfileVisualier instead of whylabs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Go to http://0.0.0.0:5000/apidocs/\n",
    "- Open /predict endpoint green tab.\n",
    "- Click Try it out.\n",
    "- Click Execute green button.\n",
    "- Check the response and code, if 200, the API is working!\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 5: Mess with Data to Showcase a Drift\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following functions aim to modify the variables distribution in order to test whylabs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def modify_random_column_values(data, value: float = np.random.uniform(low=0.0, high=10.0)) -> None:\n",
    "    random_column = None\n",
    "    data_mod = data.copy(deep=True)\n",
    "    try:\n",
    "        number_of_columns = len(data_mod.columns) - 2 # Index and label eliminated\n",
    "        random_column = data_mod.columns[np.random.randint(number_of_columns) + 1]\n",
    "        data_mod[random_column] = value\n",
    "    except Exception as ex:\n",
    "        raise f\"Error adding fix value in random column: {str(random_column)}\"\n",
    "    return data_mod\n",
    "        \n",
    "        \n",
    "def add_random_column_outliers(data, number_outliers: int = 10) -> None:\n",
    "    random_column = None\n",
    "    data_mod = data.copy(deep=True)\n",
    "    try:\n",
    "        number_of_columns = len(data_mod.columns) - 2  # Index and label eliminated\n",
    "        number_of_rows = data_mod.shape[0]\n",
    "        random_column = data_mod.columns[np.random.randint(number_of_columns) + 1]\n",
    "        for i in range(number_outliers):\n",
    "            random_row = np.random.randint(0, number_of_rows)\n",
    "            data_mod.loc[random_row, random_column] = round(np.random.uniform(low=20.0, high=50.0), 2)\n",
    "    except Exception as ex:\n",
    "        raise f\"Error adding outliers in random column: {random_column}\"\n",
    "    return data_mod"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once it's working, you can try to send continous requests to the endpoint:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = [\"sepal_length_cm\", \"sepal_width_cm\", \"petal_length_cm\", \"petal_width_cm\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# modify a variable distribution\n",
    "data_mod = add_random_column_outliers(data, 30)\n",
    "print(\"Dataset distribution modified!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "url = \"http://0.0.0.0:5000/api/v1\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "healthy = requests.get(f\"{url}/health\")\n",
    "if healthy.ok:\n",
    "    for k in range(data_mod.shape[0]):\n",
    "        # Build a payload with random values\n",
    "        payload = dict(zip(labels, data_mod.iloc[:, 0:4].values[k]))\n",
    "        print(payload)\n",
    "        response = requests.post(f\"{url}/predict\", json=payload)\n",
    "        if response.ok:\n",
    "            print(response.json())\n",
    "            time.sleep(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}